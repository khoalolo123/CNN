{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8912088,"sourceType":"datasetVersion","datasetId":5358911}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\n\n# Đọc dữ liệu\ntrain_df = pd.read_csv('/kaggle/input/vnews8td-main/VNews8td-main/train.tsv', sep='\\t', names=['text', 'label'])\nval_df = pd.read_csv('/kaggle/input/vnews8td-main/VNews8td-main/val.tsv', sep='\\t', names=['text', 'label'])\ntest_df = pd.read_csv('/kaggle/input/vnews8td-main/VNews8td-main/test.tsv', sep='\\t', names=['text', 'label'] )\n\n# Kết hợp dữ liệu\ndf = pd.concat([train_df, val_df, test_df])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T05:55:37.743719Z","iopub.execute_input":"2024-07-12T05:55:37.744061Z","iopub.status.idle":"2024-07-12T05:55:44.396150Z","shell.execute_reply.started":"2024-07-12T05:55:37.744032Z","shell.execute_reply":"2024-07-12T05:55:44.395371Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-12T05:55:51.407301Z","iopub.execute_input":"2024-07-12T05:55:51.407673Z","iopub.status.idle":"2024-07-12T05:55:51.428206Z","shell.execute_reply.started":"2024-07-12T05:55:51.407645Z","shell.execute_reply":"2024-07-12T05:55:51.427349Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                text    label\n0  Ba Lan sa thải HLV Santos sau sáu trận. Liên đ...  thethao\n1  Trữ trứng để sinh con được bao lâu?. Tôi 32 tu...  suckhoe\n2  Thường xuyên đau lưng là bệnh gì?. Lưng vợ tôi...  suckhoe\n3  Người mẹ bỏ chữa ung thư để tìm sự sống cho co...  doisong\n4  Nguy cơ Covid đồng nhiễm virus, vi khuẩn gây b...  suckhoe","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ba Lan sa thải HLV Santos sau sáu trận. Liên đ...</td>\n      <td>thethao</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Trữ trứng để sinh con được bao lâu?. Tôi 32 tu...</td>\n      <td>suckhoe</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Thường xuyên đau lưng là bệnh gì?. Lưng vợ tôi...</td>\n      <td>suckhoe</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Người mẹ bỏ chữa ung thư để tìm sự sống cho co...</td>\n      <td>doisong</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Nguy cơ Covid đồng nhiễm virus, vi khuẩn gây b...</td>\n      <td>suckhoe</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Tiền xử lý DL\n","metadata":{}},{"cell_type":"code","source":"# Mã hóa nhãn\nunique_labels = np.unique(df['label'])\nnum_class = len(unique_labels)\nlEnc = LabelEncoder()\nlEnc.fit(unique_labels)\n\nprint(unique_labels)\nprint(lEnc.transform(unique_labels))\n\ntrain_labels = lEnc.transform(train_df['label'])\nval_labels = lEnc.transform(val_df['label'])\ntest_labels = lEnc.transform(test_df['label'])\n\n# Chuyển nhãn thành tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlabels = train_labels.tolist() + val_labels.tolist() + test_labels.tolist()\nlabels = torch.LongTensor(labels).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T05:55:56.257466Z","iopub.execute_input":"2024-07-12T05:55:56.257821Z","iopub.status.idle":"2024-07-12T05:55:56.605713Z","shell.execute_reply.started":"2024-07-12T05:55:56.257792Z","shell.execute_reply":"2024-07-12T05:55:56.604855Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['doisong' 'giaoduc' 'khoahoc' 'kinhte' 'suckhoe' 'thegioi' 'thethao'\n 'thoisu']\n[0 1 2 3 4 5 6 7]\n","output_type":"stream"}]},{"cell_type":"code","source":"from string import punctuation\nimport re\n\ndef vi_clean_str(input_str: str) -> str:\n    my_punctuation = punctuation.replace('_', '')\n    output_str = input_str.translate(str.maketrans('', '', my_punctuation))\n    output_str = output_str.replace('_,', '')\n    output_str = output_str.replace('_.', '')\n    output_str = output_str.replace('…', '')\n    output_str = output_str.replace('-', '_')\n    output_str = output_str.replace('–', '_')\n    output_str = output_str.replace('\\u200b_\\u200b', '')\n    output_str = output_str.replace('\\u200b', '')\n    output_str = output_str.replace('‘', '_')\n    output_str = output_str.replace('’', '_')\n    output_str = output_str.replace('“', '_')\n    output_str = output_str.replace('”', '_')\n    output_str = ' '.join(output_str.split())\n    return output_str.lower()\n\ntrain_df['clean_text'] = train_df['text'].apply(vi_clean_str)\nval_df['clean_text'] = val_df['text'].apply(vi_clean_str)\ntest_df['clean_text'] = test_df['text'].apply(vi_clean_str)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T05:56:01.047349Z","iopub.execute_input":"2024-07-12T05:56:01.048180Z","iopub.status.idle":"2024-07-12T05:56:02.329912Z","shell.execute_reply.started":"2024-07-12T05:56:01.048148Z","shell.execute_reply":"2024-07-12T05:56:02.329073Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df['clean_text']","metadata":{"execution":{"iopub.status.busy":"2024-07-12T05:56:32.645216Z","iopub.execute_input":"2024-07-12T05:56:32.645840Z","iopub.status.idle":"2024-07-12T05:56:32.654598Z","shell.execute_reply.started":"2024-07-12T05:56:32.645808Z","shell.execute_reply":"2024-07-12T05:56:32.652696Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0        ba lan sa thải hlv santos sau sáu trận liên đo...\n1        trữ trứng để sinh con được bao lâu tôi 32 tuổi...\n2        thường xuyên đau lưng là bệnh gì lưng vợ tôi t...\n3        người mẹ bỏ chữa ung thư để tìm sự sống cho co...\n4        nguy cơ covid đồng nhiễm virus vi khuẩn gây bệ...\n                               ...                        \n31740    nhật bản ra sức tìm lại vàng son ngành chip ch...\n31741    ông bùi hoàng phương làm thứ trưởng thông tin ...\n31742    cựu vô địch major đòi tẩy chay giải golf náo n...\n31743    14 triết lý sống của người nhật người nhật luô...\n31744    ngậm cam chanh có giảm ngủ ngáy tôi nghe mọi n...\nName: clean_text, Length: 31745, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Tạo từ điển từ các văn bản\nall_texts = train_df['clean_text'].tolist() + val_df['clean_text'].tolist() + test_df['clean_text'].tolist()\nvectorizer = TfidfVectorizer(max_features=5000)\nvectorizer.fit(all_texts)\n\n# Tạo đặc trưng cho các tập\nX_train = vectorizer.transform(train_df['clean_text']).toarray()\nX_val = vectorizer.transform(val_df['clean_text']).toarray()\nX_test = vectorizer.transform(test_df['clean_text']).toarray()\n\n# Chuyển thành tensor\nX_train_tensor = torch.tensor(X_train, dtype=torch.float).to(device)\nX_val_tensor = torch.tensor(X_val, dtype=torch.float).to(device)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float).to(device)\ntrain_labels_tensor = torch.tensor(train_labels, dtype=torch.long).to(device)\nval_labels_tensor = torch.tensor(val_labels, dtype=torch.long).to(device)\ntest_labels_tensor = torch.tensor(test_labels, dtype=torch.long).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T05:56:38.019957Z","iopub.execute_input":"2024-07-12T05:56:38.020675Z","iopub.status.idle":"2024-07-12T05:56:45.246747Z","shell.execute_reply.started":"2024-07-12T05:56:38.020641Z","shell.execute_reply":"2024-07-12T05:56:45.245812Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Huấn luyện mô hình","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.nn.functional as F\n\n# Định nghĩa mô hình CNN\nclass CNN(nn.Module):\n    def __init__(self, num_features, num_classes):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv1d(in_channels=1, out_channels=100, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(in_channels=100, out_channels=100, kernel_size=3, padding=1)\n        self.fc = nn.Linear(num_features * 100, num_classes)\n        \n    def forward(self, x):\n        x = x.unsqueeze(1)  # Thêm kênh vào\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = x.view(x.size(0), -1)  # Flatten\n        x = self.fc(x)\n        return F.log_softmax(x, dim=1)\n\nnum_features = X_train_tensor.shape[1]\nnum_classes = num_class\nmodel = CNN(num_features, num_classes).to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\n# Tạo DataLoader\ntrain_dataset = TensorDataset(X_train_tensor, train_labels_tensor)\nval_dataset = TensorDataset(X_val_tensor, val_labels_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T05:56:53.228877Z","iopub.execute_input":"2024-07-12T05:56:53.229530Z","iopub.status.idle":"2024-07-12T05:56:54.610105Z","shell.execute_reply.started":"2024-07-12T05:56:53.229500Z","shell.execute_reply":"2024-07-12T05:56:54.609281Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Huấn luyện mô hình\ndef train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20):\n    for epoch in range(num_epochs):\n        model.train()\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        \n        # Đánh giá mô hình\n        model.eval()\n        val_loss = 0\n        correct = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                outputs = model(inputs)\n                val_loss += criterion(outputs, labels).item()\n                pred = outputs.argmax(dim=1, keepdim=True)\n                correct += pred.eq(labels.view_as(pred)).sum().item()\n        \n        val_loss /= len(val_loader.dataset)\n        accuracy = correct / len(val_loader.dataset)\n        \n        print(f'Epoch: {epoch + 1}, Val Loss: {val_loss:.4f}, Val Accuracy: {accuracy:.4f}')\n\ntrain_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T12:43:41.035147Z","iopub.execute_input":"2024-07-11T12:43:41.035791Z","iopub.status.idle":"2024-07-11T12:50:00.074727Z","shell.execute_reply.started":"2024-07-11T12:43:41.035758Z","shell.execute_reply":"2024-07-11T12:50:00.073697Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch: 1, Val Loss: 0.0052, Val Accuracy: 0.8895\nEpoch: 2, Val Loss: 0.0044, Val Accuracy: 0.9105\nEpoch: 3, Val Loss: 0.0046, Val Accuracy: 0.9058\nEpoch: 4, Val Loss: 0.0052, Val Accuracy: 0.8982\nEpoch: 5, Val Loss: 0.0062, Val Accuracy: 0.8976\nEpoch: 6, Val Loss: 0.0076, Val Accuracy: 0.8913\nEpoch: 7, Val Loss: 0.0091, Val Accuracy: 0.8924\nEpoch: 8, Val Loss: 0.0103, Val Accuracy: 0.8884\nEpoch: 9, Val Loss: 0.0116, Val Accuracy: 0.8911\nEpoch: 10, Val Loss: 0.0124, Val Accuracy: 0.8915\nEpoch: 11, Val Loss: 0.0135, Val Accuracy: 0.8895\nEpoch: 12, Val Loss: 0.0141, Val Accuracy: 0.8915\nEpoch: 13, Val Loss: 0.0148, Val Accuracy: 0.8900\nEpoch: 14, Val Loss: 0.0153, Val Accuracy: 0.8911\nEpoch: 15, Val Loss: 0.0155, Val Accuracy: 0.8869\nEpoch: 16, Val Loss: 0.0153, Val Accuracy: 0.8837\nEpoch: 17, Val Loss: 0.0135, Val Accuracy: 0.8811\nEpoch: 18, Val Loss: 0.0146, Val Accuracy: 0.8846\nEpoch: 19, Val Loss: 0.0160, Val Accuracy: 0.8846\nEpoch: 20, Val Loss: 0.0167, Val Accuracy: 0.8840\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ndef evaluate_model(model, test_loader):\n    model.eval()\n    y_pred = []\n    y_true = []\n\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            y_pred.extend(predicted.cpu().numpy())\n            y_true.extend(labels.cpu().numpy())\n\n    return y_true, y_pred\n\ny_true, y_pred = evaluate_model(model, test_loader)\nprint(classification_report(y_true, y_pred, target_names=lEnc.classes_))","metadata":{"execution":{"iopub.status.busy":"2024-07-11T13:04:35.281284Z","iopub.execute_input":"2024-07-11T13:04:35.281666Z","iopub.status.idle":"2024-07-11T13:04:37.447720Z","shell.execute_reply.started":"2024-07-11T13:04:35.281636Z","shell.execute_reply":"2024-07-11T13:04:37.446717Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     doisong       0.62      0.62      0.62       473\n     giaoduc       0.84      0.85      0.85       637\n     khoahoc       0.80      0.78      0.79       595\n      kinhte       0.81      0.82      0.81       867\n     suckhoe       0.94      0.93      0.93      1917\n     thegioi       0.91      0.91      0.91      1966\n     thethao       0.99      0.98      0.98      1626\n      thoisu       0.80      0.83      0.81      1034\n\n    accuracy                           0.88      9115\n   macro avg       0.84      0.84      0.84      9115\nweighted avg       0.88      0.88      0.88      9115\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Câu cần dự đoán\nnew_sentence = \"Đà Nẵng xem xét dừng hoạt động khách sạn xả thải ra biển. Chủ tịch TP Đà Nẵng Lê Trung Chinh nói sẽ dừng hoạt động nhà hàng, khách sạn không chịu đấu nối hệ thống xử lý nước thải, xả chui ra môi trường biển.\"\npreprocessed_sentence = preprocess_text(new_sentence)\n# Chuyển câu mới thành vector đặc trưng\nnew_sentence_vector = vectorizer.transform([preprocessed_sentence]).toarray()\nnew_sentence_tensor = torch.tensor(new_sentence_vector, dtype=torch.float).to(device)\n# Dự đoán nhãn của câu mới\nmodel.eval()\nwith torch.no_grad():\n    output = model(new_sentence_tensor)\n    predicted_label = output.argmax(dim=1).cpu().numpy()[0]\n\n# Chuyển nhãn dự đoán từ số thành tên nhãn\npredicted_label_name = lEnc.inverse_transform([predicted_label])[0]\nprint(f'Dự đoán nhãn: {predicted_label_name}')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T13:07:04.208655Z","iopub.execute_input":"2024-07-11T13:07:04.209056Z","iopub.status.idle":"2024-07-11T13:07:04.219678Z","shell.execute_reply.started":"2024-07-11T13:07:04.209025Z","shell.execute_reply":"2024-07-11T13:07:04.218693Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Dự đoán nhãn: thoisu\n","output_type":"stream"}]}]}